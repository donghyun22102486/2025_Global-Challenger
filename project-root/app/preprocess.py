# preprocess.py
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Set

# -----------------------------
# ì„¤ì •(í•„ìš”ì‹œ ì¡°ì •)
# -----------------------------
_MISSING_TOKENS = {"", "-", "--", "na", "n/a", "none", "null", "nan", "ë¬´", "ì—†ìŒ"}
_DEFAULT_THRESHOLDS = {
    "high_missing_ratio": 0.98,  # ê²°ì¸¡ ë¹„ìœ¨ ë†’ìœ¼ë©´ ë“œë
    "high_cardinality_ratio": 0.98,  # ë¬¸ìí˜• ê³ ìœ ê°’ ë¹„ìœ¨ ë†’ìœ¼ë©´ ID/í‚¤ë¡œ íŒë‹¨
    "near_perfect_corr": 0.9999,  # ìˆ˜ì¹˜í˜• ìƒê´€ ~1ì´ë©´ ì¤‘ë³µ íŒë‹¨
}


# ==============================
# ìœ í‹¸
# ==============================
def _coerce_pseudo_missing(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        if pd.api.types.is_object_dtype(df[col]) or pd.api.types.is_string_dtype(
            df[col]
        ):
            df[col] = df[col].astype(str).str.strip()
            df[col] = df[col].replace({t: np.nan for t in _MISSING_TOKENS}, regex=False)
    return df


def _apply_missing_strategy_series(s: pd.Series, strategy: str) -> pd.Series:
    if strategy == "drop":
        return s.dropna()
    if strategy == "mean" and pd.api.types.is_numeric_dtype(s):
        return s.fillna(s.mean())
    if strategy == "median" and pd.api.types.is_numeric_dtype(s):
        return s.fillna(s.median())
    if strategy == "mode":
        mode = s.mode()
        return s.fillna(mode.iloc[0] if not mode.empty else s)
    if strategy == "zero" and pd.api.types.is_numeric_dtype(s):
        return s.fillna(0)
    if strategy == "ffill":
        return s.fillna(method="ffill")
    if strategy == "none":
        return s
    # fallback
    return (
        s.fillna("missing")
        if not pd.api.types.is_numeric_dtype(s)
        else s.fillna(s.mean())
    )


def _iqr_clip(s: pd.Series) -> pd.Series:
    if not pd.api.types.is_numeric_dtype(s) or s.dropna().empty:
        return s
    q1, q3 = s.quantile(0.25), s.quantile(0.75)
    iqr = q3 - q1
    lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr
    return s.clip(lower=lo, upper=hi)


def _zscore_clip(s: pd.Series, z: float = 3.0) -> pd.Series:
    if not pd.api.types.is_numeric_dtype(s) or s.dropna().empty:
        return s
    mu, sd = s.mean(), s.std(ddof=0)
    if sd == 0 or np.isnan(sd):
        return s
    lo, hi = mu - z * sd, mu + z * sd
    return s.clip(lower=lo, upper=hi)


def _apply_outlier_strategy_series(
    s: pd.Series, strategy: str, params: Dict[str, Any] = None
) -> pd.Series:
    params = params or {}
    if strategy == "iqr":
        return _iqr_clip(s)
    if strategy == "zscore":
        return _zscore_clip(s, float(params.get("z", 3.0)))
    if strategy == "clip":
        lo = params.get("min")
        hi = params.get("max")
        if lo is None or hi is None:
            return _iqr_clip(s)  # ì•ˆì „ í´ë¦½
        return s.clip(lower=lo, upper=hi)
    return s  # "none" ë˜ëŠ” ë¯¸ì§€ì •


# ==============================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ==============================
def run_numeric_preprocessing(df: pd.DataFrame, llm_response: dict) -> pd.DataFrame:
    print("ğŸ”§ ì „ì²˜ë¦¬ ì‹œì‘...")

    # (A) ê°€ì§œ ê²°ì¸¡ì¹˜ ì •ê·œí™”
    df = _coerce_pseudo_missing(df)

    # (A0) ì›ì²œ ì»¬ëŸ¼ ì •ê·œí™”: ê³µë°±/ë”°ì˜´í‘œ ì œê±° (rename ì´ì „)
    def _strip_quotes_ws(s: str) -> str:
        return str(s).strip().strip("'").strip('"')

    _old = list(df.columns)
    df.columns = [_strip_quotes_ws(c) for c in df.columns]
    if _old != list(df.columns):
        try:
            preview = {
                str(o): str(n) for o, n in zip(_old, df.columns)
            }  # ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥ë  ìˆ˜ ìˆìŒ
            print(
                f"ğŸ§¼ ì›ì²œ ì»¬ëŸ¼ ì •ê·œí™”(ê³µë°±/ë”°ì˜´í‘œ ì œê±°) ì˜ˆì‹œ: {list(preview.items())[:10]}"
            )
        except Exception:
            print("ğŸ§¼ ì›ì²œ ì»¬ëŸ¼ ì •ê·œí™” ì™„ë£Œ")

    # (B) ì»¬ëŸ¼ëª… ë³€ê²½ â€” LLM ì˜¤ì—¼ ë°©ì§€(í‚¤/ê°’ ëª¨ë‘ ì •ì œ)
    raw_mapping = (llm_response or {}).get("column_mapping", {}) or {}

    def _clean_name(x: str) -> str:
        return str(x).strip().strip("'").strip('"')

    # 1) í‚¤/ê°’ ëª¨ë‘ ì •ì œ
    _cleaned_items = [(_clean_name(k), _clean_name(v)) for k, v in raw_mapping.items()]
    # 2) í˜„ì¬ DFì— ì¡´ì¬í•˜ëŠ” í‚¤ë§Œ
    safe_mapping = {k: v for k, v in _cleaned_items if k in df.columns}
    # 3) ê°’ ì¤‘ë³µ ì œê±°(ë¨¼ì € ë“±ì¥í•œ ê²ƒ ìš°ì„ )
    seen = set()
    dedup_mapping = {}
    for k, v in safe_mapping.items():
        if v not in seen:
            dedup_mapping[k] = v
            seen.add(v)

    if dedup_mapping:
        df.rename(columns=dedup_mapping, inplace=True)
        print(f"âœ… ì»¬ëŸ¼ëª… ë³€ê²½(ì •ì œ) ì™„ë£Œ: {list(dedup_mapping.items())[:10]} ...")
    else:
        print("â„¹ï¸ ì ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª… ë³€ê²½ ì—†ìŒ")

    # (C) íŒŒìƒë³€ìˆ˜ ìƒì„± â€” ì‹¤íŒ¨ ì›ì¸ ë¡œê¹…
    for feature in (llm_response or {}).get("suggested_features", []):
        if not isinstance(feature, dict):
            print(f"âš ï¸ ì˜ëª»ëœ feature í˜•ì‹ (dict ì•„ë‹˜): {feature}")
            continue
        name = feature.get("name")
        formula = feature.get("formula")
        if not (name and formula):
            print(f"âš ï¸ name/formula ëˆ„ë½: {feature}")
            continue
        try:
            df[name] = df.eval(formula)
            print(f"âœ… {name} ìƒì„± ì™„ë£Œ (ìˆ˜ì‹: {formula})")
        except NameError as e:
            print(
                f"âš ï¸ {name} ìƒì„± ì‹¤íŒ¨(NameError): {e} | ì‚¬ìš© ê°€ëŠ¥ ì»¬ëŸ¼ ì˜ˆì‹œ: {list(df.columns)[:10]} ..."
            )
        except Exception as e:
            print(f"âš ï¸ {name} ìƒì„± ì‹¤íŒ¨: {e}")

    # (D) ë°ì´í„° ì •ì œ ì¶”ì²œ + íƒ€ê¹ƒ ë³´í˜¸
    cleaning = (llm_response or {}).get("data_cleaning_recommendations", {}) or {}
    keep_columns: Set[str] = set((cleaning.get("keep_columns") or []))

    target_col = ((llm_response or {}).get("target_column") or "").strip()
    if target_col:
        keep_columns.add(target_col)  # ğŸ‘ˆ íƒ€ê¹ƒ ê°•ì œ ë³´í˜¸

    # (E) ì„ê³„ì¹˜ ì„¤ì •
    thr_cfg = (llm_response or {}).get("drop_thresholds", {}) or {}
    high_missing_thr = float(
        thr_cfg.get("high_missing_ratio", _DEFAULT_THRESHOLDS["high_missing_ratio"])
    )
    high_card_thr = float(
        thr_cfg.get(
            "high_cardinality_ratio", _DEFAULT_THRESHOLDS["high_cardinality_ratio"]
        )
    )
    corr_thr = float(
        thr_cfg.get("near_perfect_corr", _DEFAULT_THRESHOLDS["near_perfect_corr"])
    )

    # (F) íŒíŠ¸ ê¸°ë°˜ ë“œë(ë³´í˜¸ ì œì™¸)
    drop_columns_hint = cleaning.get("drop_columns", {}) or {}
    if drop_columns_hint:
        hinted = [
            c
            for c in drop_columns_hint.keys()
            if c in df.columns and c not in keep_columns
        ]
        if hinted:
            df = df.drop(columns=hinted)
            print(f"ğŸ—‘ï¸ íŒíŠ¸ ê¸°ë°˜ ë“œë: {hinted}")

    # (G) ì¤‘ë³µ í–‰ ì œê±°
    drop_duplicates_flag = (cleaning.get("drop_duplicates", {}) or {}).get(
        "recommended", False
    )
    if drop_duplicates_flag:
        before = len(df)
        df = df.drop_duplicates().reset_index(drop=True)
        after = len(df)
        print(f"ğŸ§¹ ì¤‘ë³µ í–‰ ì œê±°: {before} â†’ {after}")

    # (H1) ìƒìˆ˜ ì»¬ëŸ¼ ë“œë â€” ë³´í˜¸
    drop_cols = [
        c
        for c in df.columns
        if c not in keep_columns and df[c].nunique(dropna=True) <= 1
    ]
    if drop_cols:
        df = df.drop(columns=drop_cols)
        print(f"ğŸ—‘ï¸ ìƒìˆ˜ ì»¬ëŸ¼ ë“œë: {drop_cols}")

    # (H2) ê²°ì¸¡ ê³¼ë‹¤ ë“œë â€” ë³´í˜¸
    miss_ratio = df.isna().mean()
    drop_cols = [
        c
        for c in miss_ratio.index
        if miss_ratio[c] >= high_missing_thr and c not in keep_columns
    ]
    if drop_cols:
        df = df.drop(columns=drop_cols)
        print(f"ğŸ—‘ï¸ ê²°ì¸¡ ê³¼ë‹¤ ì»¬ëŸ¼ ë“œë(â‰¥{high_missing_thr:.3f}): {drop_cols}")

    # (H3) ê³ ìœ ê°’ ê³¼ë‹¤ ë¬¸ì ì»¬ëŸ¼(ID/í‚¤) â€” ë³´í˜¸
    n = len(df)
    drop_cols = []
    for c in df.select_dtypes(include=["object", "string"]).columns:
        if c in keep_columns:
            continue
        nun = df[c].nunique(dropna=True)
        if n > 0 and (nun / n) >= high_card_thr:
            drop_cols.append(c)
    if drop_cols:
        df = df.drop(columns=drop_cols)
        print(f"ğŸ—‘ï¸ ê³ ìœ ê°’ ê³¼ë‹¤ ë¬¸ì ì»¬ëŸ¼ ë“œë(â‰¥{high_card_thr:.3f}): {drop_cols}")

    # (H4) ì™„ì „ ì¤‘ë³µ ì»¬ëŸ¼ ë“œë â€” ë³´í˜¸
    tmp = df.fillna("__NA__SENTINEL__")
    dup_mask = tmp.T.duplicated(keep="first")
    drop_cols = [col for col in tmp.columns[dup_mask] if col not in keep_columns]
    if drop_cols:
        df = df.drop(columns=drop_cols)
        print(f"ğŸ—‘ï¸ ì™„ì „ ì¤‘ë³µ ì»¬ëŸ¼ ë“œë: {drop_cols}")

    # (H5) (ìˆ˜ì¹˜í˜•) ìƒê´€ ~1 ì¤‘ë³µ ì»¬ëŸ¼ â€” ë³´í˜¸
    num_df = df.select_dtypes(include="number")
    if num_df.shape[1] > 1:
        corr = num_df.corr()
        cols = num_df.columns.tolist()
        to_drop = set()
        for i in range(len(cols)):
            for j in range(i + 1, len(cols)):
                a, b = cols[i], cols[j]
                if a in keep_columns or b in keep_columns:
                    continue
                val = corr.iloc[i, j]
                if pd.notna(val) and abs(val) >= corr_thr:
                    to_drop.add(b)  # ë’¤ì— ë‚˜ì˜¨ bë¥¼ ë²„ë¦¼
        drop_cols = sorted(list(to_drop))
        if drop_cols:
            df = df.drop(columns=drop_cols)
            print(f"ğŸ—‘ï¸ ìƒê´€ ~1 ì¤‘ë³µ ì»¬ëŸ¼ ë“œë(â‰¥{corr_thr:.5f}): {drop_cols}")

    # (I) ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì—´ë³„ ì „ëµ ìš°ì„  â†’ ì „ì—­ ì „ëµ ë³´ì¡°
    per_col_missing: Dict[str, Dict[str, str]] = (llm_response or {}).get(
        "missing_strategy_per_column", {}
    ) or {}
    global_missing = (llm_response or {}).get("missing_strategy", None)

    if per_col_missing or global_missing:
        for col in list(df.columns):
            if col in per_col_missing:
                strat = per_col_missing[col].get("strategy", "none")
                before_na = df[col].isna().sum()
                df[col] = _apply_missing_strategy_series(df[col], strat)
                after_na = df[col].isna().sum()
                print(f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬({col}): {strat} | {before_na} -> {after_na}")
        if global_missing:
            for col in list(df.columns):
                if df[col].isna().any() and col not in per_col_missing:
                    before_na = df[col].isna().sum()
                    df[col] = _apply_missing_strategy_series(df[col], global_missing)
                    after_na = df[col].isna().sum()
                    print(
                        f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬(ì „ì—­, {col}): {global_missing} | {before_na} -> {after_na}"
                    )
    else:
        num_cols = df.select_dtypes(include="number").columns
        cat_cols = df.select_dtypes(exclude="number").columns
        df[num_cols] = df[num_cols].fillna(df[num_cols].mean())
        df[cat_cols] = df[cat_cols].fillna("missing")
        print("âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ê¸°ë³¸(mean/missing) ì ìš©")

    # (J) ì´ìƒì¹˜ ì²˜ë¦¬
    per_col_outlier: Dict[str, Any] = (llm_response or {}).get(
        "outlier_strategy_per_column", {}
    ) or {}
    for col, cfg in per_col_outlier.items():
        if col not in df.columns:
            continue
        strat = cfg.get("strategy", "none")
        params = {k: v for k, v in cfg.items() if k != "strategy"}  # z, min, max ë“±
        if pd.api.types.is_numeric_dtype(df[col]):
            before_desc = df[col].describe()
            df[col] = _apply_outlier_strategy_series(df[col], strat, params)
            after_desc = df[col].describe()
            print(
                f"âœ… ì´ìƒì¹˜ ì²˜ë¦¬({col}): {strat} | mean {before_desc['mean']:.4f} â†’ {after_desc['mean']:.4f}"
            )
        else:
            print(f"â„¹ï¸ ì´ìƒì¹˜ ì²˜ë¦¬ ìŠ¤í‚µ({col}): ìˆ˜ì¹˜í˜• ì•„ë‹˜")

    # (K) ë²”ì£¼í˜• â†’ ì›í•« ì¸ì½”ë”©
    df = pd.get_dummies(df, drop_first=False)
    print("âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì›í•« ì¸ì½”ë”© ì ìš© ì™„ë£Œ")

    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    return df
